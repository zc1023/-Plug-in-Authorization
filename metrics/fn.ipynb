{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dino distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dino distance\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def dino_distance(image1, image2):\n",
    "    processor = AutoImageProcessor.from_pretrained('/home/czhou/data/dinov2-base')\n",
    "    model = AutoModel.from_pretrained('/home/czhou/data/dinov2-base')\n",
    "    image1 = Image.open(image1).convert('RGB')\n",
    "    image2 = Image.open(image2).convert('RGB')\n",
    "    inputs = processor(images=[image1,image2], return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    # print(outputs)\n",
    "    pooler_output = outputs.pooler_output\n",
    "    img1_embedding = pooler_output[0].detach().numpy()\n",
    "    img2_embedding = pooler_output[1].detach().numpy()\n",
    "    norm1 =  np.linalg.norm(img1_embedding)\n",
    "    norm2 =  np.linalg.norm(img2_embedding)\n",
    "    dot_product = np.dot(img1_embedding, img2_embedding)\n",
    "    distance = abs(dot_product / (norm1 * norm2))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dino_distance(\"/home/czhou/Cplug-in/data/Claude_Monet/1/False/0_False.jpg\",\"/home/czhou/Cplug-in/data/Claude_Monet/1/False/0_False.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip distance\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import os\n",
    "from cleanfid import fid\n",
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "def get_clip_score(images, text, w=1):\n",
    "    images = [Image.open(image) for image in images]    \n",
    "\n",
    "    #Load CLIP model\n",
    "    model = SentenceTransformer(\"/home/czhou/data/clip-ViT-B-32\")\n",
    "\n",
    "    #Encode an image:\n",
    "    img_emb = model.encode(images)\n",
    "\n",
    "    #Encode text descriptions\n",
    "    text_emb = model.encode(text)\n",
    "\n",
    "    #Compute cosine similarities \n",
    "    cos_scores = util.cos_sim(img_emb, text_emb)\n",
    "    return cos_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clip_score([\"/home/czhou/Cplug-in/data/Claude_Monet/1/False/0_False.jpg\"],\"Monet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torch_fidelity import calculate_metrics\n",
    "def fid_kid_score(orign,non_infring):\n",
    "    metrics = calculate_metrics(\n",
    "        input1 = orign, \n",
    "        input2 = non_infring,\n",
    "        cuda=True,\n",
    "        isc=False,\n",
    "        kid=True,\n",
    "        fid=True,\n",
    "        kid_subset_size=40,\n",
    "        verbose=False\n",
    "    )\n",
    "    return metrics[\"frechet_inception_distance\"],metrics[\"kernel_inception_distance_mean\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/home/czhou/Cplug-in/van_gogh/target/base/\"\n",
    "\n",
    "non_infring = \"/home/czhou/Cplug-in/van_gogh/target/non_infring/\"\n",
    "fid,kid = fid_kid_score(base,non_infring)\n",
    "print(f\"fid: {(fid)}, kid: {(kid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LPIPS\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import lpips\n",
    "\n",
    "def LPIPS_score(img_path1, img_path2):\n",
    "    # 初始化LPIPS模型\n",
    "    loss_fn_alex = lpips.LPIPS(net='alex')  # 使用AlexNet作为特征提取器\n",
    "    # 或者使用vgg:\n",
    "    # loss_fn_vgg = lpips.LPIPS(net='vgg')\n",
    "\n",
    "    # 加载并预处理图像\n",
    "    def load_image(image_path, transform=None):\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        if transform is None:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((256, 256)),  # 调整大小到256x256\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 标准化\n",
    "            ])\n",
    "        return transform(img).unsqueeze(0)  # 添加batch维度\n",
    "\n",
    "\n",
    "    # 加载图像\n",
    "    img_tensor1 = load_image(img_path1)\n",
    "    img_tensor2 = load_image(img_path2)\n",
    "\n",
    "    # 确保两个张量在相同的设备上 (CPU或GPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    loss_fn_alex = loss_fn_alex.to(device)\n",
    "    img_tensor1 = img_tensor1.to(device)\n",
    "    img_tensor2 = img_tensor2.to(device)\n",
    "\n",
    "    # 计算LPIPS距离\n",
    "    distance = loss_fn_alex(img_tensor1, img_tensor2)\n",
    "\n",
    "    return distance.detach().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LPIPS_score(\"/home/czhou/Cplug-in/data/Claude_Monet/1/False/0_False.jpg\",\"/home/czhou/Cplug-in/data/Claude_Monet/2/False/0_False.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = [\n",
    "     \"Leonardo da Vinci\", \n",
    " \"Vincent van Gogh\" ,\n",
    " \"Pablo Picasso\" ,\n",
    " \"Claude Monet\" ,\n",
    " \"Michelangelo\" ,\n",
    " \"Rembrandt van Rijn\", \n",
    " \"Salvador Dalí\" ,\n",
    " \"Johannes Vermeer\", \n",
    " \"Frida Kahlo\" ,\n",
    " \"Henri Matisse\",\n",
    "]\n",
    "\n",
    "imageries = [\n",
    "    \"vase of flowers\",\n",
    "    \"bowl of fruit\",\n",
    "    \"still life with candles\",\n",
    "    \"landscape with rolling hills\",\n",
    "    \"cityscape with buildings\",\n",
    "    \"forest with sunlight filtering through trees\",\n",
    "    \"portrait of a person\",\n",
    "    \"quiet beach at sunset\",\n",
    "    \"mountain range with snow\",\n",
    "    \"tranquil lake with reflections\",\n",
    "    \"barn in a rural setting\",\n",
    "    \"bustling street market\",\n",
    "    \"boat on a calm river\",\n",
    "    \"group of animals in a field\",\n",
    "    \"crowded café scene\",\n",
    "    \"horse grazing in a pasture\",\n",
    "    \"vintage clock on a mantelpiece\",\n",
    "    \"window with a view of the countryside\",\n",
    "    \"room with antique furniture\",\n",
    "    \"close-up of a tree's bark and leaves\"\n",
    "             ]\n",
    "styles = [style.replace(\" \", \"_\") for style in styles]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seen contents\n",
    "target_style_dir = \"/home/czhou/Cplug-in/data\"\n",
    "fids = []\n",
    "kids = []\n",
    "lpips = []\n",
    "dino = []\n",
    "clips = []\n",
    "for style in styles:\n",
    "    style_dir = os.path.join(target_style_dir, style)\n",
    "    for i in range(10):\n",
    "        false_dir =  os.path.join(style_dir, str(i),\"False\")\n",
    "        true_dir  =  os.path.join(style_dir, str(i),\"True\")\n",
    "        fid,kid = fid_kid_score(false_dir, true_dir)\n",
    "        fids.append(fid)\n",
    "        kids.append(kid)\n",
    "        for j in range(2):\n",
    "            false_image = os.path.join(false_dir, str(j)+\".jpg\")\n",
    "            true_image  = os.path.join(true_dir, str(j)+\".jpg\")\n",
    "            lpips.append(LPIPS_score(false_image, true_image))\n",
    "            dino.append(dino_distance(false_image, true_image))\n",
    "            clips.append(get_clip_score(true_image,f\"{imageries[i]} by {style}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cplug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
